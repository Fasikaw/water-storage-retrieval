{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase I: Automatic Water Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import required modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import ee\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize Google Earth Engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Path to your GEE folder. This is going to be used for saving assets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_assets = \"your path here\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentinel-2 Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cloud and Shadow Masking\n",
    "\n",
    "The following function masks clouds and shadows based on the SCL band and an user defined threshold value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clouds_shadows_mask(image):\n",
    "    \n",
    "    shadows_mask = image.select('SCL').eq(3).Not() # Shadow-free pixels\n",
    "    clouds_mask = image.select('SCL').lt(7).Or(image.select('SCL').gt(9)) # Cloud-free pixels\n",
    "    empirical_clouds_mask = image.select('B2').lte(1500) # Cloud-free pixels\n",
    "    clouds_mask = clouds_mask.And(empirical_clouds_mask) # Cloud-free pixels\n",
    "    mask = shadows_mask.And(clouds_mask) # Cloud-shadow-free pixels\n",
    "    \n",
    "    return image.updateMask(mask).copyProperties(image,[\"system:time_start\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflectance\n",
    "\n",
    "This function scales the imagery to the original reflectance values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reflectance(image):\n",
    "        \n",
    "    return ee.Image(image.multiply(0.0001).copyProperties(image,[\"system:time_start\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complete Pipeline\n",
    "\n",
    "The complete preprocessing pipeline function can mask, clip, calculate the reflectance and smooth the input image (images). Only the 10 m bands are saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessingPipeline(images,ROI,masking = True,calculateReflectance = True,smoothing = True):        \n",
    "    \n",
    "    original = images\n",
    "    \n",
    "    if type(images) == ee.imagecollection.ImageCollection:        \n",
    "        if masking:            \n",
    "            images = images.map(clouds_shadows_mask)\n",
    "        images = images.median().select(['B2','B3','B4','B8']).clip(ROI)        \n",
    "        if calculateReflectance:            \n",
    "            images = reflectance(images)\n",
    "        if smoothing:            \n",
    "            images = images.focal_median(radius = 1,kernelType = \"square\")\n",
    "    \n",
    "    elif type(images) == ee.image.Image:        \n",
    "        if masking:            \n",
    "            images = clouds_shadows_mask(images)\n",
    "        images = images.select(['B2','B3','B4','B8']).clip(ROI)        \n",
    "        if calculateReflectance:            \n",
    "            images = reflectance(images)\n",
    "        if smoothing:            \n",
    "            images = images.focal_median(radius = 1,kernelType = \"square\")\n",
    "    \n",
    "    return images  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatic Water Mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code creates automatically a water mask from an input Sentinel-2 image. The process goes as follows:\n",
    "\n",
    "1. Multiband Index (NDWI or GNDVI) is calculated depending on `index`.\n",
    "2. Seeds image is generated according to the `seedSpacing` and the `gridType`.\n",
    "3. Run SNIC algorithm using 10 m bands + Multiband Index.\n",
    "4. Compute the total of seeds used.\n",
    "5. Compute total training samples to use. Depends on `pTrain`.\n",
    "6. Extract samples from segmented image.\n",
    "7. Run k-means on training set. It dependes on `k`.\n",
    "8. Cluster the segmented image.\n",
    "9. Determine the water cluster. It depends on `index`.\n",
    "10. Extract the selected cluster as water.\n",
    "\n",
    "Compactness and connectivity are set to 1 and 8 in the SNIC algorithm, respectively. These parameters can also be tuned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def automaticWaterMask(image,ROI,index = \"GNDVI\",seedSpacing = 20,gridType = \"square\",scale = 10,k = 3,pTrain = 0.8):\n",
    "        \n",
    "    if index == \"GNDVI\":\n",
    "        idx = image.normalizedDifference(['B8','B3'])\n",
    "    elif index == \"NDWI\":\n",
    "        idx = image.normalizedDifference(['B3','B8'])\n",
    "    \n",
    "    seeds = ee.Algorithms.Image.Segmentation.seedGrid(seedSpacing,gridType)\n",
    "    \n",
    "    SNIC = ee.Algorithms.Image.Segmentation.SNIC(image = ee.Image.cat([image.select(['B2','B3','B4','B8']),idx]),                                             \n",
    "                                                 compactness = 1,\n",
    "                                                 connectivity = 8,                                                 \n",
    "                                                 seeds = seeds)\n",
    "    \n",
    "    SNIC = SNIC.select(['B2_mean','B3_mean','B4_mean','B8_mean','nd_mean','clusters'], ['B2','B3','B4','B8','idx','clusters'])\n",
    "    \n",
    "    nseeds = seeds.reduceRegion(reducer = ee.Reducer.count(),geometry = ROI,scale = scale).getInfo()['seeds']\n",
    "    \n",
    "    ntrain = round(nseeds*pTrain)\n",
    "    \n",
    "    if ntrain > 10000:\n",
    "        ntrain = 10000\n",
    "    \n",
    "    objectPropertiesImage = SNIC.select(['B2','B3','B4','B8','idx'])\n",
    "    \n",
    "    X_train = objectPropertiesImage.sample(scale = scale,numPixels = ntrain,region = ROI,geometries = True)\n",
    "    \n",
    "    kmeans = ee.Clusterer.wekaKMeans(k)\n",
    "    kmeans = kmeans.train(X_train)\n",
    "    clusterImage = objectPropertiesImage.cluster(kmeans)\n",
    "    \n",
    "    values = []\n",
    "    for i in range(k):\n",
    "        cluster_mask = clusterImage.eq(i)\n",
    "        idx_clusterMasked = idx.updateMask(cluster_mask)\n",
    "        mean_value = idx_clusterMasked.reduceRegion(reducer = ee.Reducer.mean(),geometry = ROI,scale = 10)\n",
    "        values.append(mean_value.getInfo()['nd'])        \n",
    "        \n",
    "    if index == \"GNDVI\":\n",
    "        cluster_water = np.array(values).argmin().item()\n",
    "    elif index == \"NDWI\":\n",
    "        cluster_water = np.array(values).argmax().item()    \n",
    "    \n",
    "    water_mask = clusterImage.eq(cluster_water)\n",
    "    \n",
    "    return water_mask, idx, SNIC, X_train, clusterImage, ntrain, nseeds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix Image\n",
    "\n",
    "Confusion matrix is calculated for all the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imageConfusionMatrix(truthImage,predictedImage,ROI,scale = 10):\n",
    "        \n",
    "    predictedImage = predictedImage.multiply(10)\n",
    "    confusion_image = truthImage.add(predictedImage)\n",
    "\n",
    "    TN = confusion_image.eq(0)\n",
    "    TN = TN.updateMask(TN).reduceRegion(ee.Reducer.count(),ROI,scale = scale).getInfo()['nd']    \n",
    "\n",
    "    FN = confusion_image.eq(1)\n",
    "    FN = FN.updateMask(FN).reduceRegion(ee.Reducer.count(),ROI,scale = scale).getInfo()['nd']    \n",
    "\n",
    "    FP = confusion_image.eq(10)\n",
    "    FP = FP.updateMask(FP).reduceRegion(ee.Reducer.count(),ROI,scale = scale).getInfo()['nd']    \n",
    "\n",
    "    TP = confusion_image.eq(11)\n",
    "    TP = TP.updateMask(TP).reduceRegion(ee.Reducer.count(),ROI,scale = scale).getInfo()['nd']    \n",
    "        \n",
    "    return [TP,FP,TN,FN], confusion_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The validation process requires to test multiple levels for Grid Type (G), Seed Spacing (S), number of clusters (K) and training size (T). The following function run the validation and exports a pandas data frame with the results of the confusion matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validateWaterMask(image,ROI,wmt,G = [\"square\",\"hex\"],S = [10,20,30,40],K = [3,4,5],T = [0.5,0.75,0.8,0.9,1,1.5,2]):\n",
    "\n",
    "    gt = []\n",
    "    ss = []\n",
    "    ks = []\n",
    "    cm = []\n",
    "    tm = []\n",
    "    nt = []\n",
    "    ns = []\n",
    "    pt = []\n",
    "\n",
    "    i = 0\n",
    "\n",
    "    for pTrain in T:\n",
    "        for gridType in G:\n",
    "            for seedSpacing in S:                    \n",
    "                for k in K:                    \n",
    "\n",
    "                    gt.append(gridType)\n",
    "                    ss.append(seedSpacing)            \n",
    "                    ks.append(k)\n",
    "                    pt.append(pTrain)\n",
    "\n",
    "                    start = time.time()\n",
    "                    wm, idx, SNIC, X_train, clusterImage, ntrain, nseeds = automaticWaterMask(image,\n",
    "                                                                                              ROI,\n",
    "                                                                                              index = \"NDWI\",\n",
    "                                                                                              seedSpacing = seedSpacing,\n",
    "                                                                                              gridType = gridType,\n",
    "                                                                                              k = k,\n",
    "                                                                                              pTrain = pTrain)\n",
    "                    \n",
    "                    end = time.time()\n",
    "                    print(end - start,\"s\")\n",
    "                    tm.append(end - start)\n",
    "                    nt.append(ntrain)\n",
    "                    ns.append(nseeds)\n",
    "\n",
    "                    cm.append(imageConfusionMatrix(wmt,wm,ROI))\n",
    "\n",
    "                    i = i + 1\n",
    "\n",
    "    cm_df = pd.DataFrame(np.array(cm))\n",
    "    gt_df = pd.DataFrame(np.array(gt))\n",
    "    ss_df = pd.DataFrame(np.array(ss))\n",
    "    ks_df = pd.DataFrame(np.array(ks))\n",
    "    tm_df = pd.DataFrame(np.array(tm))\n",
    "    nt_df = pd.DataFrame(np.array(nt))\n",
    "    ns_df = pd.DataFrame(np.array(ns))\n",
    "    pt_df = pd.DataFrame(np.array(pt))\n",
    "\n",
    "    df = pd.concat([gt_df,ss_df,ks_df,nt_df,ns_df,tm_df,pt_df,cm_df],axis = 1)\n",
    "    df.columns = ['GridType','SeedSpacing','k','nTrain','Superpixels','Time','TrainingPrSuperpixels','TP','FP','TN','FN']\n",
    "\n",
    "    df['TotalPixels'] = df['TP'] + df['FP'] + df['FN'] + df['TN']\n",
    "    df['SuperpixelsProportion'] = df['Superpixels']/df['TotalPixels']\n",
    "    df['TrainingPrPixels'] = df['nTrain']/df['TotalPixels']\n",
    "\n",
    "    df['FPR'] = df['FP']/(df['FP'] + df['TN'])\n",
    "    df['FNR'] = df['FN']/(df['FN'] + df['TP'])\n",
    "    df['Sensitivity'] = 1 - df['FNR']\n",
    "    df['Specificity'] = 1 - df['FPR']\n",
    "\n",
    "    df['FDR'] = df['FP']/(df['FP'] + df['TP'])\n",
    "    df['FOR'] = df['FN']/(df['FN'] + df['TN'])\n",
    "    df['Precision'] = 1 - df['FDR']\n",
    "    df['NPV'] = 1 - df['FOR']\n",
    "\n",
    "    df['Accuracy'] = (df['TP'] + df['TN'])/(df['TP'] + df['TN'] + df['FP'] + df['FN'])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Results to GEE Assets and Google Drive\n",
    "\n",
    "The following function saves the results to your specified path in GEE and your Google Drive. The best levels for each factor are already defined, but can be changed. Downloaded imagery can be found at ../data/phase-I/imagery/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveToAssetsDrive(image,ROI,wmt,path_assets,suffix,driveFolder,index = \"NDWI\",seedSpacing = 10,gridType = \"square\",k = 4,pTrain = 2):\n",
    "\n",
    "    wm, idx, SNIC, X_train, clusterImage, ntrain, nseeds = automaticWaterMask(image,\n",
    "                                                                              ROI,\n",
    "                                                                              index = index,\n",
    "                                                                              seedSpacing = seedSpacing,\n",
    "                                                                              gridType = gridType,\n",
    "                                                                              k = k,\n",
    "                                                                              pTrain = pTrain)\n",
    "\n",
    "    ee.batch.Export.image.toAsset(image = wm,\n",
    "                                  description = \"WMp\",\n",
    "                                  assetId = path_assets + \"WMp_\" + suffix,\n",
    "                                  scale = 10,\n",
    "                                  region = ROI).start()\n",
    "    \n",
    "    ee.batch.Export.image.toAsset(image = wmt,\n",
    "                                  description = \"WMt\",\n",
    "                                  assetId = path_assets + \"WMt_\" + suffix,\n",
    "                                  scale = 10,\n",
    "                                  region = ROI).start()\n",
    "    \n",
    "    ee.batch.Export.image.toAsset(image = image,\n",
    "                                  description = \"Preprocessed\",\n",
    "                                  assetId = path_assets + \"Pre_\" + suffix,\n",
    "                                  scale = 10,\n",
    "                                  region = ROI).start()\n",
    "    \n",
    "\n",
    "    cm, cm_image = imageConfusionMatrix(wmt,wm,ROI)\n",
    "\n",
    "    toExport = [image,wm,idx,SNIC,clusterImage,wmt,cm_image]\n",
    "    prefix = [\"Preprocessed\",\"WMp\",\"Idx\",\"SNIC\",\"Clusters\",\"WMt\",\"CM\"] \n",
    "    \n",
    "    toFilenames = []\n",
    "    for p in prefix:\n",
    "        toFilenames.append(p + '_' + suffix)\n",
    "\n",
    "    for i in range(len(toExport)):\n",
    "        if i == 3:\n",
    "            ee.batch.Export.image.toDrive(image = toExport[i].toFloat(),\n",
    "                                          description = toFilenames[i],\n",
    "                                          folder = driveFolder,\n",
    "                                          scale = 10,\n",
    "                                          region = ROI).start()\n",
    "        else:\n",
    "            ee.batch.Export.image.toDrive(image = toExport[i],\n",
    "                                          description = toFilenames[i],\n",
    "                                          folder = driveFolder,\n",
    "                                          scale = 10,\n",
    "                                          region = ROI).start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Study Cases\n",
    "\n",
    "For the four reservoirs the water masks are derived. Validation process was carried out and statistical analysis was done in `R`. After statistical analysis, the model with the best performance was $G=square$, $S=10$, $K=4$ and $T=2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alto-Lindoso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROI = ee.Geometry.Rectangle([-8.2260339,41.8596283,-8.0632989,41.9309290])\n",
    "alto_lindoso = ee.Image(\"COPERNICUS/S2_SR/20191022T112121_20191022T112445_T29TNG\")\n",
    "alto_lindoso = preprocessingPipeline(alto_lindoso,ROI,masking = False)\n",
    "truthMask_alto_lindoso = alto_lindoso.normalizedDifference(['B3','B8']).gt(-0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = validateWaterMask(alto_lindoso,ROI,truthMask_alto_lindoso)\n",
    "df.to_csv(\"../data/phase-I/cm_alto_lindoso.csv\",index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveToAssetsDrive(alto_lindoso,ROI,truthMask_alto_lindoso,path_assets,\"Alto_Lindoso\",\"GEE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bubal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROI = ee.Geometry.Rectangle([-0.3245736,42.6798840,-0.2969361,42.7209728])\n",
    "bubal = ee.Image(\"COPERNICUS/S2_SR/20170824T105031_20170824T105240_T30TYN\")\n",
    "bubal = preprocessingPipeline(bubal,ROI,masking = False)\n",
    "truthMask_bubal = bubal.normalizedDifference(['B3','B8']).gt(0.66)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = validateWaterMask(bubal,ROI,truthMask_bubal)\n",
    "df.to_csv(\"../data/phase-I/cm_bubal.csv\",index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveToAssetsDrive(bubal,ROI,truthMask_bubal,path_assets,\"Bubal\",\"GEE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Canelles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROI = ee.Geometry.Rectangle([0.5664387,41.9718079,0.7096043,42.1213370])\n",
    "canelles1 = ee.Image(\"COPERNICUS/S2_SR/20181102T105209_20181102T105345_T30TYM\")\n",
    "canelles2 = ee.Image(\"COPERNICUS/S2_SR/20181102T105209_20181102T105345_T31TBG\")\n",
    "canelles3 = ee.Image(\"COPERNICUS/S2_SR/20181102T105209_20181102T105345_T31TCG\")\n",
    "canelles = ee.ImageCollection([canelles1,canelles2,canelles3])\n",
    "canelles = preprocessingPipeline(canelles,ROI)\n",
    "truthMask_canelles = canelles.normalizedDifference(['B3','B8']).gt(-0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = validateWaterMask(canelles,ROI,truthMask_canelles)\n",
    "df.to_csv(\"../data/phase-I/cm_canelles.csv\",index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveToAssetsDrive(canelles,ROI,truthMask_canelles,path_assets,\"Canelles\",\"GEE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROI = ee.Geometry.Rectangle([0.1912200,42.1501858,0.2537043,42.3090388])\n",
    "grado1 = ee.Image(\"COPERNICUS/S2_SR/20170814T105031_20170814T105517_T30TYM\")\n",
    "grado2 = ee.Image(\"COPERNICUS/S2_SR/20170913T105021_20170913T105335_T30TYM\")\n",
    "grado = ee.ImageCollection([grado1,grado2])\n",
    "grado = preprocessingPipeline(grado,ROI,masking = False)\n",
    "truthMask_grado = grado.normalizedDifference(['B3','B8']).gt(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = validateWaterMask(grado,ROI,truthMask_grado)\n",
    "df.to_csv(\"../data/phase-I/cm_grado.csv\",index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveToAssetsDrive(grado,ROI,truthMask_grado,path_assets,\"Grado\",\"GEE\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
