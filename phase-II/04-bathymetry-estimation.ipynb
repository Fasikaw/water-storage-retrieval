{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase II: Satellite Derived Bathymetry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import required modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, cross_validate\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor as rf\n",
    "from sklearn.ensemble import GradientBoostingRegressor as gb\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import r2_score as r2\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function computes the RMSE for different water depths starting in `h` +/ `delta` and ending in `maxh` (at jumps of `jump`) for a predicted `y_pred` against an actual `y_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmseByDepth(y_test,y_pred,h = 2.5,delta = 2.5,jump = 5,maxh = 110):\n",
    "\n",
    "    hList = []\n",
    "    rmseList = []\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    while h < maxh:\n",
    "        hList.append(h)\n",
    "        idx = np.where((y_test >= h - delta) & (y_test < h + delta))\n",
    "        rmse = mse(y_test[idx],y_pred[idx],squared = False)\n",
    "        rmseList.append(rmse)        \n",
    "        h = h + jump\n",
    "    \n",
    "    df['h'] = hList\n",
    "    df['rmse'] = rmseList\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the complete datasets for each study case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_A = pd.read_csv(\"../data/phase-II/complete-dataset/data_A.csv\")\n",
    "data_B = pd.read_csv(\"../data/phase-II/complete-dataset/data_B.csv\")\n",
    "data_C = pd.read_csv(\"../data/phase-II/complete-dataset/data_C.csv\")\n",
    "data_G = pd.read_csv(\"../data/phase-II/complete-dataset/data_G.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract target values and input features for each dataset. Extract also 5% as test from each one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_A = data_A.iloc[:,3:]\n",
    "y_A = data_A.iloc[:,0]\n",
    "\n",
    "X_B = data_B.iloc[:,3:]\n",
    "y_B = data_B.iloc[:,0]\n",
    "\n",
    "X_C = data_C.iloc[:,3:]\n",
    "y_C = data_C.iloc[:,0]\n",
    "\n",
    "X_G = data_G.iloc[:,3:]\n",
    "y_G = data_G.iloc[:,0]\n",
    "\n",
    "X_train_A, X_test_A, y_train_A, y_test_A = train_test_split(X_A,y_A,test_size = 0.05,random_state = 20)\n",
    "X_train_B, X_test_B, y_train_B, y_test_B = train_test_split(X_B,y_B,test_size = 0.05,random_state = 20)\n",
    "X_train_C, X_test_C, y_train_C, y_test_C = train_test_split(X_C,y_C,test_size = 0.05,random_state = 20)\n",
    "X_train_G, X_test_G, y_train_G, y_test_G = train_test_split(X_G,y_G,test_size = 0.05,random_state = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gather all training datasets in one (including target values). Gather target values of the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.concat([X_train_A,X_train_B,X_train_C,X_train_G])\n",
    "y_train = pd.concat([y_train_A,y_train_B,y_train_C,y_train_G])\n",
    "y_test = np.array(pd.concat([y_test_A,y_test_B,y_test_C,y_test_G]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardize data using the training dataset. Scale all other datasets. Test sets remain separated so each reservoir can be evaluated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "\n",
    "X_test_A = scaler.transform(X_test_A)\n",
    "X_test_B = scaler.transform(X_test_B)\n",
    "X_test_C = scaler.transform(X_test_C)\n",
    "X_test_G = scaler.transform(X_test_G)\n",
    "\n",
    "X_A = scaler.transform(X_A)\n",
    "X_B = scaler.transform(X_B)\n",
    "X_C = scaler.transform(X_C)\n",
    "X_G = scaler.transform(X_G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression (LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10-fold cross-validate the linear regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = pd.DataFrame(cross_validate(LinearRegression(),X_train,y_train,cv = 10,scoring = [\"neg_root_mean_squared_error\",\"r2\"]))\n",
    "cv_results['test_neg_root_mean_squared_error'] = cv_results['test_neg_root_mean_squared_error']*-1\n",
    "cv_results.to_csv(\"../data/phase-II/results/LR/cvresults-LR.csv\",index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_mean = cv_results['test_neg_root_mean_squared_error'].mean()\n",
    "rmse_std = cv_results['test_neg_root_mean_squared_error'].std()\n",
    "print(\"RMSE: %0.3f +/- %0.3f\" % (rmse_mean,rmse_std/np.sqrt(10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit all training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LinearRegression().fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make predictions on the test set for each reservoir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_A = reg.predict(X_test_A)\n",
    "y_pred_B = reg.predict(X_test_B)\n",
    "y_pred_C = reg.predict(X_test_C)\n",
    "y_pred_G = reg.predict(X_test_G)\n",
    "\n",
    "ys_A = pd.DataFrame({\"y_test\":y_test_A,\"y_pred\":y_pred_A})\n",
    "ys_B = pd.DataFrame({\"y_test\":y_test_B,\"y_pred\":y_pred_B})\n",
    "ys_C = pd.DataFrame({\"y_test\":y_test_C,\"y_pred\":y_pred_C})\n",
    "ys_G = pd.DataFrame({\"y_test\":y_test_G,\"y_pred\":y_pred_G})\n",
    "\n",
    "ys_A.to_csv(\"../data/phase-II/results/LR/ytest-ypred-A-LR.csv\",index = False)\n",
    "ys_B.to_csv(\"../data/phase-II/results/LR/ytest-ypred-B-LR.csv\",index = False)\n",
    "ys_C.to_csv(\"../data/phase-II/results/LR/ytest-ypred-C-LR.csv\",index = False)\n",
    "ys_G.to_csv(\"../data/phase-II/results/LR/ytest-ypred-G-LR.csv\",index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print RMSE and $R^2$ for each reservoir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Alto-Lindoso = R2: %0.2f, RMSE %0.3f\" % (r2(y_test_A,y_pred_A),mse(y_test_A,y_pred_A,squared = False)))\n",
    "print(\"Bubal = R2: %0.2f, RMSE %0.3f\" % (r2(y_test_B,y_pred_B),mse(y_test_B,y_pred_B,squared = False)))\n",
    "print(\"Canelles = R2: %0.2f, RMSE %0.3f\" % (r2(y_test_C,y_pred_C),mse(y_test_C,y_pred_C,squared = False)))\n",
    "print(\"Grado = R2: %0.2f, RMSE %0.3f\" % (r2(y_test_G,y_pred_G),mse(y_test_G,y_pred_G,squared = False)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print global results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.concatenate((y_pred_A,y_pred_B,y_pred_C,y_pred_G))\n",
    "print(\"Total = R2: %0.2f, RMSE %0.3f\" % (r2(y_test,y_pred),mse(y_test,y_pred,squared = False)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute RMSE of the predicted values through water depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmseDepth = rmseByDepth(y_test,y_pred)\n",
    "rmseDepth.to_csv(\"../data/phase-II/results/LR/depth-rmse-LR.csv\",index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save global test and predicted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys = pd.DataFrame({\"y_test\":y_test,\"y_pred\":y_pred})\n",
    "ys.to_csv(\"../data/phase-II/results/LR/ytest-ypred-GLOBAL-LR.csv\",index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make predictions over all the dataset for each reservoir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_A['z_pred'] = reg.predict(X_A)\n",
    "data_B['z_pred'] = reg.predict(X_B)\n",
    "data_C['z_pred'] = reg.predict(X_C)\n",
    "data_G['z_pred'] = reg.predict(X_G)\n",
    "\n",
    "data_A.to_csv(\"../data/phase-II/results/LR/data-all-A-LR.csv\",index = False)\n",
    "data_B.to_csv(\"../data/phase-II/results/LR/data-all-B-LR.csv\",index = False)\n",
    "data_C.to_csv(\"../data/phase-II/results/LR/data-all-C-LR.csv\",index = False)\n",
    "data_G.to_csv(\"../data/phase-II/results/LR/data-all-G-LR.csv\",index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest (RF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Broader Tuning\n",
    "\n",
    "First, the total estimators and the maximum features used for splitting are tuned in a broader approach. This tuning was 3-fold cross-validated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\"n_estimators\":[100,200,300,400,500],\"max_features\":[\"auto\",\"sqrt\"]}\n",
    "rfReg = GridSearchCV(rf(),parameters,cv = 3,scoring = \"neg_root_mean_squared_error\")\n",
    "rfReg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = pd.DataFrame(rfReg.cv_results_)\n",
    "cv_results = cv_results.drop(columns = ['params'])\n",
    "cv_results.to_csv(\"../data/phase-II/results/RF/gridsearchcv-results-rf-broader.csv\",index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results of this cross-validation were analyzed by an ANOVA and LSD tests. The maximum number of features for splitting was selected as $\\sqrt{n}$ and 100 total estimators. A narrower tuning was done taking these results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Narrower Tuning\n",
    "\n",
    "In the narrower tuning only the total estimators were tuned. This tuning was 5-fold cross-validated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\"n_estimators\":np.arange(10,151,10)}\n",
    "rfReg = GridSearchCV(rf(max_features = \"sqrt\"),parameters,cv = 5,scoring = \"neg_root_mean_squared_error\")\n",
    "rfReg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = pd.DataFrame(rfReg.cv_results_)\n",
    "cv_results = cv_results.drop(columns = ['params'])\n",
    "cv_results.to_csv(\"../data/phase-II/results/RF/gridsearchcv-results-rf-narrower.csv\",index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-validation results were analyzed in R. Significant differences were not found and a 20 total estimators were selected taking time into account.\n",
    "\n",
    "A Random Forest with the tuned parameters was fitted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestRF = rf(max_features = \"sqrt\",n_estimators = 20).fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features importances were saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fidf = pd.DataFrame({\"feature\":X_A.columns,\"feature_importances\":bestRF.feature_importances_})\n",
    "fidf.to_csv(\"../data/phase-II/results/RF/feature-importances-rf.csv\",index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make predictions on the test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_A = bestRF.predict(X_test_A)\n",
    "y_pred_B = bestRF.predict(X_test_B)\n",
    "y_pred_C = bestRF.predict(X_test_C)\n",
    "y_pred_G = bestRF.predict(X_test_G)\n",
    "\n",
    "ys_A = pd.DataFrame({\"y_test\":y_test_A,\"y_pred\":y_pred_A})\n",
    "ys_B = pd.DataFrame({\"y_test\":y_test_B,\"y_pred\":y_pred_B})\n",
    "ys_C = pd.DataFrame({\"y_test\":y_test_C,\"y_pred\":y_pred_C})\n",
    "ys_G = pd.DataFrame({\"y_test\":y_test_G,\"y_pred\":y_pred_G})\n",
    "\n",
    "ys_A.to_csv(\"../data/phase-II/results/RF/ytest-ypred-A-RF.csv\",index = False)\n",
    "ys_B.to_csv(\"../data/phase-II/results/RF/ytest-ypred-B-RF.csv\",index = False)\n",
    "ys_C.to_csv(\"../data/phase-II/results/RF/ytest-ypred-C-RF.csv\",index = False)\n",
    "ys_G.to_csv(\"../data/phase-II/results/RF/ytest-ypred-G-RF.csv\",index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print results for each reservoir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Alto-Lindoso = R2: %0.2f, RMSE %0.3f\" % (r2(y_test_A,y_pred_A),mse(y_test_A,y_pred_A,squared = False)))\n",
    "print(\"Bubal = R2: %0.2f, RMSE %0.3f\" % (r2(y_test_B,y_pred_B),mse(y_test_B,y_pred_B,squared = False)))\n",
    "print(\"Canelles = R2: %0.2f, RMSE %0.3f\" % (r2(y_test_C,y_pred_C),mse(y_test_C,y_pred_C,squared = False)))\n",
    "print(\"Grado = R2: %0.2f, RMSE %0.3f\" % (r2(y_test_G,y_pred_G),mse(y_test_G,y_pred_G,squared = False)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print global results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.concatenate((y_pred_A,y_pred_B,y_pred_C,y_pred_G))\n",
    "print(\"Total = R2: %0.2f, RMSE %0.3f\" % (r2(y_test,y_pred),mse(y_test,y_pred,squared = False)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute RMSE for water depths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmseDepth = rmseByDepth(y_test,y_pred)\n",
    "rmseDepth.to_csv(\"../data/phase-II/results/RF/depth-rmse-RF.csv\",index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save global data (predicted and actual)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys = pd.DataFrame({\"y_test\":y_test,\"y_pred\":y_pred})\n",
    "ys.to_csv(\"../data/phase-II/results/RF/ytest-ypred-GLOBAL-RF.csv\",index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict over the whole datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_A['z_pred'] = bestRF.predict(X_A)\n",
    "data_B['z_pred'] = bestRF.predict(X_B)\n",
    "data_C['z_pred'] = bestRF.predict(X_C)\n",
    "data_G['z_pred'] = bestRF.predict(X_G)\n",
    "\n",
    "data_A.to_csv(\"../data/phase-II/results/RF/data-all-A-RF.csv\",index = False)\n",
    "data_B.to_csv(\"../data/phase-II/results/RF/data-all-B-RF.csv\",index = False)\n",
    "data_C.to_csv(\"../data/phase-II/results/RF/data-all-C-RF.csv\",index = False)\n",
    "data_G.to_csv(\"../data/phase-II/results/RF/data-all-G-RF.csv\",index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting (GB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The maximum depth of estimators was tuned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\"max_depth\":np.arange(10,101,10)}\n",
    "gbreg = gb(n_estimators = 500,max_features = \"sqrt\",validation_fraction = 0.05,n_iter_no_change = 10,random_state = 20,tol = 0.01)\n",
    "rfReg = GridSearchCV(gbreg,parameters,cv = 5,scoring = \"neg_root_mean_squared_error\")\n",
    "rfReg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = pd.DataFrame(rfReg.cv_results_)\n",
    "cv_results = cv_results.drop(columns = ['params'])\n",
    "cv_results.to_csv(\"../data/phase-II/results/GB/gridsearchcv-results-gb.csv\",index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data was analyzed in R. Significant differences were not found. The best maximum depth was chosen as the one with the least time: 20 levels as maximum depth. Which was also the one with the lower RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestGB = rfReg.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the feature importances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fidf = pd.DataFrame({\"feature\":X_A.columns,\"feature_importances\":bestGB.feature_importances_})\n",
    "fidf.to_csv(\"../data/phase-II/results/GB/feature-importances-gb.csv\",index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the Loss function decay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_estimators = pd.DataFrame({\"estimator\":np.arange(0,bestGB.train_score_.shape[0],1),\"score\":bestGB.train_score_})\n",
    "score_estimators.to_csv(\"../data/phase-II/results/GB/score-estimators-gb.csv\",index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make predictions on the test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_A = bestGB.predict(X_test_A)\n",
    "y_pred_B = bestGB.predict(X_test_B)\n",
    "y_pred_C = bestGB.predict(X_test_C)\n",
    "y_pred_G = bestGB.predict(X_test_G)\n",
    "\n",
    "ys_A = pd.DataFrame({\"y_test\":y_test_A,\"y_pred\":y_pred_A})\n",
    "ys_B = pd.DataFrame({\"y_test\":y_test_B,\"y_pred\":y_pred_B})\n",
    "ys_C = pd.DataFrame({\"y_test\":y_test_C,\"y_pred\":y_pred_C})\n",
    "ys_G = pd.DataFrame({\"y_test\":y_test_G,\"y_pred\":y_pred_G})\n",
    "\n",
    "ys_A.to_csv(\"../data/phase-II/results/GB/ytest-ypred-A-GB.csv\",index = False)\n",
    "ys_B.to_csv(\"../data/phase-II/results/GB/ytest-ypred-B-GB.csv\",index = False)\n",
    "ys_C.to_csv(\"../data/phase-II/results/GB/ytest-ypred-C-GB.csv\",index = False)\n",
    "ys_G.to_csv(\"../data/phase-II/results/GB/ytest-ypred-G-GB.csv\",index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print results for each reservoir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Alto-Lindoso = R2: %0.2f, RMSE %0.3f\" % (r2(y_test_A,y_pred_A),mse(y_test_A,y_pred_A,squared = False)))\n",
    "print(\"Bubal = R2: %0.2f, RMSE %0.3f\" % (r2(y_test_B,y_pred_B),mse(y_test_B,y_pred_B,squared = False)))\n",
    "print(\"Canelles = R2: %0.2f, RMSE %0.3f\" % (r2(y_test_C,y_pred_C),mse(y_test_C,y_pred_C,squared = False)))\n",
    "print(\"Grado = R2: %0.2f, RMSE %0.3f\" % (r2(y_test_G,y_pred_G),mse(y_test_G,y_pred_G,squared = False)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the global results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.concatenate((y_pred_A,y_pred_B,y_pred_C,y_pred_G))\n",
    "print(\"Total = R2: %0.2f, RMSE %0.3f\" % (r2(y_test,y_pred),mse(y_test,y_pred,squared = False)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute RMSE by water depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmseDepth = rmseByDepth(y_test,y_pred)\n",
    "rmseDepth.to_csv(\"../data/phase-II/results/GB/depth-rmse-GB.csv\",index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save global predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys = pd.DataFrame({\"y_test\":y_test,\"y_pred\":y_pred})\n",
    "ys.to_csv(\"../data/phase-II/results/GB/ytest-ypred-GLOBAL-GB.csv\",index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict over the whole datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_A['z_pred'] = bestGB.predict(X_A)\n",
    "data_B['z_pred'] = bestGB.predict(X_B)\n",
    "data_C['z_pred'] = bestGB.predict(X_C)\n",
    "data_G['z_pred'] = bestGB.predict(X_G)\n",
    "\n",
    "data_A.to_csv(\"../data/phase-II/results/GB/data-all-A-GB.csv\",index = False)\n",
    "data_B.to_csv(\"../data/phase-II/results/GB/data-all-B-GB.csv\",index = False)\n",
    "data_C.to_csv(\"../data/phase-II/results/GB/data-all-C-GB.csv\",index = False)\n",
    "data_G.to_csv(\"../data/phase-II/results/GB/data-all-G-GB.csv\",index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
